{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 165,
   "id": "4bf1cf02-b3a8-44da-9a5d-51d0d78407d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "import copy\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt \n",
    "\n",
    "x_train = np.array([1,3,4,5,6])\n",
    "y_train = np.array([10,20,30,40,50])\n",
    "w=1\n",
    "b=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "id": "c4fb56b8-ee55-4612-bb28-8feffc0e7191",
   "metadata": {},
   "outputs": [],
   "source": [
    "def prediction(x,y,w,b):\n",
    "    return w*x+b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "id": "02294641-9557-46af-ae44-ac91232a5062",
   "metadata": {},
   "outputs": [],
   "source": [
    "def cost(actual,predicted):\n",
    "    return (1/2)*np.mean(actual-predicted)**2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "id": "609459aa-7909-45dd-b90a-459318dbda85",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2 4 5 6 7]\n",
      "[ -8 -16 -25 -34 -43]\n",
      "-116.80000000000001\n",
      "[ 3.42   7.756  9.924 12.092 14.26 ]\n",
      "[ -6.58  -12.244 -20.076 -27.908 -35.74 ]\n",
      "-95.51920000000001\n",
      "[ 4.580288 10.826672 13.949864 17.073056 20.196248]\n",
      "[ -5.419712  -9.173328 -16.050136 -22.926944 -29.803752]\n",
      "-78.1194944\n",
      "[ 5.52823069 13.33700458 17.24139152 21.14577846 25.05016541]\n",
      "[ -4.47176931  -6.66299542 -12.75860848 -18.85422154 -24.94983459]\n",
      "-63.893060947200006\n",
      "[ 6.30255616 15.38919126 19.93250882 24.47582637 29.01914392]\n",
      "[ -3.69744384  -4.61080874 -10.06749118 -15.52417363 -20.98085608]\n",
      "-52.261167879372785\n",
      "[ 6.93492938 17.06678785 22.13271708 27.19864631 32.26457554]\n",
      "[ -3.06507062  -2.93321215  -7.86728292 -12.80135369 -17.73542446]\n",
      "-42.75063078998542\n",
      "[ 7.45124038 18.43811146 23.931547   29.42498254 34.91841808]\n",
      "[ -2.54875962  -1.56188854  -6.068453   -10.57501746 -15.08158192]\n",
      "-34.97456321935304\n",
      "[ 7.87265741 19.55901976 25.40220093 31.2453821  37.08856327]\n",
      "[ -2.12734259  -0.44098024  -4.59779907  -8.7546179  -12.91143673]\n",
      "-28.616637895003187\n",
      "[ 8.21648814 20.47518325 26.6045308  32.73387835 38.8632259 ]\n",
      "[ -1.78351186   0.47518325  -3.3954692   -7.26612165 -11.1367741 ]\n",
      "-23.418218359620766\n",
      "[ 8.49688371 21.22394318 27.58747292 33.95100265 40.31453239]\n",
      "[-1.50311629  1.22394318 -2.41252708 -6.04899735 -9.68546761]\n",
      "-19.167837493931795\n"
     ]
    }
   ],
   "source": [
    "def gradient_descent(x, y, w, b):\n",
    "    alpha = 0.01  # Learning rate\n",
    "    iters = 10  # Number of iterations\n",
    "    dw_db = []  # To store history of w and b\n",
    "    cost_history = []  # To store history of cost\n",
    "\n",
    "    for i in range(iters):\n",
    "        # Step 1: Make predictions\n",
    "        pred = prediction(x ,y, w, b)\n",
    "        print(pred)\n",
    "        # Step 2: Compute cost\n",
    "        error = pred - y\n",
    "        print(error)\n",
    "        current_cost = cost(y, pred)\n",
    "\n",
    "        # Step 3: Compute gradients\n",
    "        dw = (1 / len(y)) * np.dot(x, error)\n",
    "        print(dw)\n",
    "        db = (1 / len(y)) * np.sum(error)    # Gradient w.r.t. b\n",
    "      \n",
    "        # Step 4: Update parameters\n",
    "        w = w - alpha * dw\n",
    "        b = b - alpha * db\n",
    "\n",
    "        # Store history\n",
    "        dw_db.append([w, b])\n",
    "        cost_history.append(current_cost)\n",
    "\n",
    "    return dw_db, cost_history\n",
    "w_b,cost=gradient_descent(x_train,y_train,w,b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "id": "a11be4ec-c399-4faf-9b82-4df0def99b3f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[2.168, 1.252], [3.1231920000000004, 1.457096], [3.9043869440000005, 1.623843744], [4.543317553472001, 1.759238602688], [5.065929232265729, 1.869000149629184], [5.493435540165583, 1.9578048373067944], [5.843181172359113, 2.0294762384074345], [6.129347551309145, 2.087140591473714], [6.363529734905352, 2.1333539786092293], [6.555208109844671, 2.1702063088967334]]\n",
      "\n",
      "[317.52, 210.32184607999997, 139.02405064544763, 91.65883879571744, 60.237985934608645, 39.4313627675897, 25.68394867864402, 16.62588807276261, 10.678385752685083, 6.79047123809654]\n"
     ]
    }
   ],
   "source": [
    "print(w_b)\n",
    "print()\n",
    "print(cost)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eadf24c8-ca03-4e4f-873f-07ae70a1649b",
   "metadata": {},
   "outputs": [],
   "source": [
    "##  practice  try on another data set \n",
    "import numpy as np \n",
    "\n",
    "x_train =np.array([3,5,7,9,11,13])\n",
    "y_train = np.array([9,25,81,222 ,313,444])\n",
    "\n",
    "\n",
    "def model_pre(x,y,w,b):\n",
    "    return w*x +b\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "2dbaaee5-eb78-453b-b033-eef113a0e52e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_cost (x,y):\n",
    "    error = (x - y)**2\n",
    "    ave_cost = 1/(2*len(x))*np.sum(error)\n",
    "    return (ave_cost)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "599fbf99-86d0-40a9-92a8-096d3bf39413",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pre_of_mod_for_G.D =[ 4  6  8 10 12 14] \n",
      "derivative of w = -1905.0\n",
      "pre_of_mod_for_G.D =[ 62.88333333 102.98333333 143.08333333 183.18333333 223.28333333\n",
      " 263.38333333] \n",
      "derivative of w = -449.6833333333332\n",
      "pre_of_mod_for_G.D =[ 76.56583333 125.6595     174.75316667 223.84683333 272.9405\n",
      " 322.03416667] \n",
      "derivative of w = -107.88694444444445\n",
      "pre_of_mod_for_G.D =[ 79.632775   130.88418056 182.13558611 233.38699167 284.63839722\n",
      " 335.88980278] \n",
      "derivative of w = -27.609823148148315\n",
      "pre_of_mod_for_G.D =[ 80.20679014 132.01039216 183.81399418 235.61759619 287.42119821\n",
      " 339.22480023] \n",
      "derivative of w = -8.752626743827136\n",
      "pre_of_mod_for_G.D =[ 80.19554432 132.17419888 184.15285343 236.13150798 288.11016254\n",
      " 340.08881709] \n",
      "derivative of w = -4.320402789146138\n",
      "pre_of_mod_for_G.D =[ 80.04706793 132.11213054 184.17719315 236.24225576 288.30731837\n",
      " 340.37238098] \n",
      "derivative of w = -3.2760058018527234\n",
      "pre_of_mod_for_G.D =[ 79.8665842  131.99716692 184.12774965 236.25833237 288.3889151\n",
      " 340.51949782] \n",
      "derivative of w = -3.027272701563561\n",
      "pre_of_mod_for_G.D =[ 79.6788053  131.86993348 184.06106166 236.25218984 288.44331802\n",
      " 340.6344462 ] \n",
      "derivative of w = -2.9654129713938646\n",
      "pre_of_mod_for_G.D =[ 79.48953476 131.7399712  183.99040764 236.24084408 288.49128052\n",
      " 340.74171696] \n",
      "derivative of w = -2.947447216202363\n"
     ]
    }
   ],
   "source": [
    "def gradient_descent (x,y):\n",
    "    alpha =0.01\n",
    "    w =1\n",
    "    b =1\n",
    "    dw_db =[]\n",
    "    cost_history = []\n",
    "    iters = 10\n",
    "    for i in range (iters):\n",
    "\n",
    "      mo_pre = model_pre(x,y,w,b)\n",
    "      print(f\"pre_of_mod_for_G.D ={mo_pre} \")\n",
    "\n",
    "      error = mo_pre - y\n",
    "      curent_cost = compute_cost(mo_pre,y)     # here i call this function for cost history \n",
    "    \n",
    "      dw = (1/len(y))*np.dot(error,x)\n",
    "      print(f\"derivative of w = {dw}\")     # taking derivative / cost change of cost function  \n",
    "      db = (1/len(y))*np.sum(error)\n",
    "\n",
    "      w =w - alpha*dw    # updating w and b after cost change by derivative \n",
    "      b =b - alpha*db\n",
    "\n",
    "      dw_db.append([w,b])\n",
    "      cost_history.append(curent_cost)\n",
    "    return dw_db , cost_history\n",
    "\n",
    "dw_db,cost_his = gradient_descent(x_train ,y_train )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "3498aae3-4373-4389-8b0d-4da6ce8950aa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "updated w and b is =[[20.05, 2.7333333333333334], [24.546833333333332, 2.925333333333333], [25.625702777777775, 2.7556666666666665], [25.90180100925926, 2.5013871111111112], [25.98932727669753, 2.2275624925925928], [26.032531304588993, 1.9494740188641977], [26.06529136260752, 1.6707101076417696], [26.095564089623156, 1.3921130308900835], [26.125218219337096, 1.1138801067446635], [26.15469269149912, 0.8360571814635827]]\n",
      "\n",
      "cost_his = [27180.0, 4584.779027777776, 3330.9143223842584, 3254.2261840774213, 3242.492075290138, 3234.363588953577, 3226.4567797381083, 3218.584925404846, 3210.7376574112322, 3202.9143348010357]\n"
     ]
    }
   ],
   "source": [
    "print(f\"updated w and b is ={dw_db}\")\n",
    "print()\n",
    "print(f\"cost_his = {cost_his}\" )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "6638c95e-cff7-42a9-a5da-3db22cbdbae1",
   "metadata": {},
   "outputs": [],
   "source": [
    "             # multi linear regression \n",
    "\n",
    "import numpy as np \n",
    "\n",
    "x_train =np.array ([[2104, 5, 1, 45], [1416, 3, 2, 40], [852, 2, 1, 35]])\n",
    "y_train = np.array([460, 232, 178])\n",
    "w_init = np.array([0.39133535, 18.75376741, -53.36032453, -26.42131618])\n",
    "b_init = 785.1811367994083\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "d2f39157-28b9-4ac9-8445-5d27ff2a8334",
   "metadata": {},
   "outputs": [],
   "source": [
    "def f_predict(x,w,b):\n",
    "     return np.dot(x,w)+b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "931f5358-7de9-4b6d-bcf8-33130eaca41f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def cost_error(pred,y):\n",
    "    \n",
    "    extract_error_for_cost  = (pred - y)**2\n",
    "\n",
    "    error = 1/(2*len(y))*np.sum(extract_error_for_cost )\n",
    "    return error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "96dca8e9-f72a-43df-9cc5-f76be47a5181",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['dw = [array([  0.39133562,  18.75376741, -53.36032453, -26.42131617])],db = [785.1811367995756]'], ['dw = [array([  0.39127081,  18.75376726, -53.36032458, -26.42131781])],db = [785.1811367599847]'], ['dw = [array([  0.4066805 ,  18.75380272, -53.36031212, -26.42092783])],db = [785.181146172801]'], ['dw = [array([ -3.25692508,  18.74537179, -53.3632748 , -26.5136452 ])],db = [785.1789083055722]'], ['dw = [array([867.75375918,  20.74979986, -52.65890681,  -4.47038142])],db = [785.7109541895351]'], ['dw = [array([-206212.29249843,    -455.79665845,    -220.12017797,\\n         -5245.18690291])],db = [659.2187213694251]'], ['dw = [array([4.90264163e+07, 1.12841623e+05, 3.95932695e+04, 1.24071866e+06])],db = [30732.348588789777]'], ['dw = [array([-1.16558759e+10, -2.68232629e+07, -9.42591470e+06, -2.94983260e+08])],db = [-7119059.538703613]'], ['dw = [array([2.77114779e+12, 6.37715073e+09, 2.24096879e+09, 7.01313345e+10])],db = [1692721437.8407354]'], ['dw = [array([-6.58831656e+14, -1.51614749e+12, -5.32783282e+11, -1.66735038e+13])],db = [-402439001845.8427]']]\n",
      "\n",
      "[1.5578904045996674e-12, 8.803827134617228e-08, 0.004976236894688905, 281.27464734920227, 15898645.686635584, 898648125777.814, 5.0794795348060424e+16, 2.8711028938252736e+21, 1.62284969758159e+26, 9.17292496414771e+30]\n"
     ]
    }
   ],
   "source": [
    "def gradient(x,y,w,b):\n",
    "    cost_history =[]\n",
    "    dw_db = []\n",
    "    alpha = 0.0001\n",
    "    ini_w =np.zeros_like(w)\n",
    "    ini_b =0\n",
    "    iters =10\n",
    "\n",
    "    for i in range(iters):\n",
    "        pred_for_GD = f_predict(x,w,b)\n",
    "        dw = 1/(len(y))*np.dot(x.T,pred_for_GD,x)\n",
    "        db = 1/(len(y))*np.sum(pred_for_GD-y)\n",
    "\n",
    "        w = w - alpha *dw\n",
    "        b = b - alpha *db\n",
    "\n",
    "\n",
    "        cost_history.append(cost_error(pred_for_GD,y))\n",
    "        dw_db.append([f\"dw = {[w]},db = {[b]}\"])\n",
    "    return dw_db, cost_history\n",
    "\n",
    "dw_db,cost_history = gradient(x_train ,y_train ,w_init,b_init ) \n",
    "print(dw_db)\n",
    "print()\n",
    "print(cost_history)\n",
    "\n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "b0162367-13b4-4405-81fd-664e95809a54",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final weights and bias:\n",
      "Weights: [-6.86785846e+34 -1.58047754e+32 -5.55389247e+31 -1.73809597e+33]\n",
      "Bias: -4.195144667742205e+31\n",
      "\n",
      "Cost history:\n",
      "[1.5578904045996674e-12, 0.0008877299667991055, 505964.2105432726, 288375735781161.6, 1.643605679105914e+23, 9.367777150430035e+31, 5.339191136639052e+40, 3.043087120433513e+49, 1.734416128877831e+58, 9.88535388261581e+66]\n"
     ]
    }
   ],
   "source": [
    "# try on another dat set \n",
    "\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "# Initialize training data\n",
    "x_train = np.array([[2104, 5, 1, 45], [1416, 3, 2, 40], [852, 2, 1, 35]])\n",
    "y_train = np.array([460, 232, 178])\n",
    "\n",
    "# Initialize weights and bias\n",
    "w_init = np.array([0.39133535, 18.75376741, -53.36032453, -26.42131618])\n",
    "b_init = 785.1811367994083\n",
    "\n",
    "\n",
    "\n",
    "# Prediction function\n",
    "def f_predict(x, w, b):\n",
    "    return np.dot(x, w) + b\n",
    "\n",
    "# Cost function\n",
    "def cost_error(pred, y):\n",
    "    error = 1/(2*len(y))*np.sum((pred - y)**2)\n",
    "    return error\n",
    "\n",
    "# Gradient descent function\n",
    "def gradient_descent(x, y, w, b, alpha, iterations):\n",
    "    cost_history = []\n",
    "    params_history = []\n",
    "\n",
    "    for i in range(iterations):\n",
    "        # Compute predictions\n",
    "        pred = f_predict(x, w, b)\n",
    "        \n",
    "        # Compute gradients\n",
    "        dw =  1/len(y)*np.dot(x.T, (pred - y))\n",
    "        db = 1/len(y)*np.sum(pred - y) \n",
    "\n",
    "        # Update weights and bias\n",
    "        w = w - alpha * dw\n",
    "        b = b - alpha * db\n",
    "\n",
    "        # Store cost and parameters\n",
    "        cost_history.append(cost_error(pred, y))\n",
    "        params_history.append({\"w\": w.copy(), \"b\": b})\n",
    "\n",
    "    return params_history, cost_history\n",
    "\n",
    "# Run gradient descent\n",
    "alpha = 0.01  # Learning rate\n",
    "iterations = 10 # Number of iterations\n",
    "params_history, cost_history = gradient_descent(x_train, y_train, w_init, b_init, alpha, iterations)\n",
    "\n",
    "# Print results\n",
    "print(\"Final weights and bias:\")\n",
    "print(f\"Weights: {params_history[-1]['w']}\")\n",
    "print(f\"Bias: {params_history[-1]['b']}\\n\")\n",
    "print(\"Cost history:\")\n",
    "print(cost_history)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c1dc56f-5a12-43fe-a292-cd8d69f51c6b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c04131f-2d92-4b9c-9a87-4bba0b3b5f64",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
